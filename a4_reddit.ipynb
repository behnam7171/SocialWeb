{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*****************************************************\n",
    "# The Social Web Assignment 4: Recommendation\n",
    "\n",
    "- Instructors: Jacco van Ossenbruggen.\n",
    "- TAs: Ayesha Noorain, Alex Boyko, Caio Silva, Elena Beretta, Mirthe Dankloff.\n",
    "- Exercises for Hands-on session 4 \n",
    "*****************************************************\n",
    "\n",
    "In this notebook you will use the similarity measures to provide recommendations by comparing users and content based on expressed preferences (ratings). You will also explore textual similarity using a very popular natural language processing library, NLTK. Finally, you will explore recommendations on the Reddit platform."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Required packages:\n",
    "* feedparser, praw,  nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1334,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: feedparser in /Users/alirezasoltaninezhad/opt/anaconda3/lib/python3.8/site-packages (6.0.8)\r\n",
      "Requirement already satisfied: sgmllib3k in /Users/alirezasoltaninezhad/opt/anaconda3/lib/python3.8/site-packages (from feedparser) (1.0.0)\r\n",
      "Requirement already satisfied: praw in /Users/alirezasoltaninezhad/opt/anaconda3/lib/python3.8/site-packages (7.5.0)\r\n",
      "Requirement already satisfied: websocket-client>=0.54.0 in /Users/alirezasoltaninezhad/opt/anaconda3/lib/python3.8/site-packages (from praw) (1.2.1)\r\n",
      "Requirement already satisfied: prawcore<3,>=2.1 in /Users/alirezasoltaninezhad/opt/anaconda3/lib/python3.8/site-packages (from praw) (2.3.0)\r\n",
      "Requirement already satisfied: update-checker>=0.18 in /Users/alirezasoltaninezhad/opt/anaconda3/lib/python3.8/site-packages (from praw) (0.18.0)\r\n",
      "Requirement already satisfied: requests<3.0,>=2.6.0 in /Users/alirezasoltaninezhad/opt/anaconda3/lib/python3.8/site-packages (from prawcore<3,>=2.1->praw) (2.26.0)\r\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /Users/alirezasoltaninezhad/opt/anaconda3/lib/python3.8/site-packages (from requests<3.0,>=2.6.0->prawcore<3,>=2.1->praw) (2.0.4)\r\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/alirezasoltaninezhad/opt/anaconda3/lib/python3.8/site-packages (from requests<3.0,>=2.6.0->prawcore<3,>=2.1->praw) (1.26.7)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/alirezasoltaninezhad/opt/anaconda3/lib/python3.8/site-packages (from requests<3.0,>=2.6.0->prawcore<3,>=2.1->praw) (3.2)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/alirezasoltaninezhad/opt/anaconda3/lib/python3.8/site-packages (from requests<3.0,>=2.6.0->prawcore<3,>=2.1->praw) (2021.10.8)\r\n",
      "Requirement already satisfied: nltk in /Users/alirezasoltaninezhad/opt/anaconda3/lib/python3.8/site-packages (3.6.1)\r\n",
      "Requirement already satisfied: tqdm in /Users/alirezasoltaninezhad/opt/anaconda3/lib/python3.8/site-packages (from nltk) (4.62.3)\r\n",
      "Requirement already satisfied: regex in /Users/alirezasoltaninezhad/opt/anaconda3/lib/python3.8/site-packages (from nltk) (2021.8.3)\r\n",
      "Requirement already satisfied: joblib in /Users/alirezasoltaninezhad/opt/anaconda3/lib/python3.8/site-packages (from nltk) (1.0.1)\r\n",
      "Requirement already satisfied: click in /Users/alirezasoltaninezhad/opt/anaconda3/lib/python3.8/site-packages (from nltk) (8.0.3)\r\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "!pip install feedparser\n",
    "!pip install praw\n",
    "!pip install nltk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the snippets below, you can find:\n",
    "* creation of a small toy database in form of a dictionary of dictionaries;\n",
    "* issuing several similarity measures based on critics' preferences; and\n",
    "* use those values to obtain meaningful statistics pertaining a user."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Movie preferences of movie critics\n",
    "As example data, let us define a python dictionary of movie critics and their ratings of a small set of movies\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1335,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "critics = {\n",
    "    'Lisa Rose': {\n",
    "        'Lady in the Water': 2.5,\n",
    "        'Snakes on a Plane': 3.5,\n",
    "        'Just My Luck': 3.0,\n",
    "        'Superman Returns': 3.5,\n",
    "        'You, Me and Dupree': 2.5,\n",
    "        'The Night Listener': 3.0,\n",
    "    },\n",
    "    'Gene Seymour': {\n",
    "        'Lady in the Water': 3.0,\n",
    "        'Snakes on a Plane': 3.5,\n",
    "        'Just My Luck': 1.5,\n",
    "        'Superman Returns': 5.0,\n",
    "        'The Night Listener': 3.0,\n",
    "        'You, Me and Dupree': 3.5,\n",
    "    },\n",
    "    'Michael Phillips': {\n",
    "        'Lady in the Water': 2.5,\n",
    "        'Snakes on a Plane': 3.0,\n",
    "        'Superman Returns': 3.5,\n",
    "        'The Night Listener': 4.0,\n",
    "    },\n",
    "    'Claudia Puig': {\n",
    "        'Snakes on a Plane': 3.5,\n",
    "        'Just My Luck': 3.0,\n",
    "        'The Night Listener': 4.5,\n",
    "        'Superman Returns': 4.0,\n",
    "        'You, Me and Dupree': 2.5,\n",
    "    },\n",
    "    'Mick LaSalle': {\n",
    "        'Lady in the Water': 3.0,\n",
    "        'Snakes on a Plane': 4.0,\n",
    "        'Just My Luck': 2.0,\n",
    "        'Superman Returns': 3.0,\n",
    "        'The Night Listener': 3.0,\n",
    "        'You, Me and Dupree': 2.0,\n",
    "    },\n",
    "    'Jack Matthews': {\n",
    "        'Lady in the Water': 3.0,\n",
    "        'Snakes on a Plane': 4.0,\n",
    "        'The Night Listener': 3.0,\n",
    "        'Superman Returns': 5.0,\n",
    "        'You, Me and Dupree': 3.5,\n",
    "    },\n",
    "    'Toby': {'Snakes on a Plane': 4.5,\n",
    "             'You, Me and Dupree': 1.0,\n",
    "             'Superman Returns': 4.0},\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Exercise 1: Finding Similar Users**\n",
    "\n",
    "In the code below, two different simililarity measures are used: Euclidean distance and the Pearson correlation. If you are not familiar with them, we recommend you look them up to deepen your understanding."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Euclidian distance"
   ]
  },
  {
   "attachments": {
    "image.png": {
     "image/png": "iVBORw0KGgoAAAANSUhEUgAAAzUAAABECAYAAAC4ehsVAAAABHNCSVQICAgIfAhkiAAAIABJREFUeF7tnU2MZUlW36eKkSwzkruqkTcg0a/KtmwMQ2cNtoRZTL1se01njeQl7sySZe/oqjaaBcj0y2LDBshqFvbC9rxs75DMZCHZG0tTN9uWLSGYrhowHwumXmHMAiQ6G1kW/gD8/1VHDFHREffjvZfvI/N/pH/de0+cOHHiHyfixn33vazPfMZiBsyAGTADZsAMmAEzYAbMgBkwA2bADJgBM2AGzIAZMANmwAyYATNgBsyAGTADZsAMmAEzYAbMgBkwA2ZgMANXBtdwBTNgBsyAGTADZsAMmAEzsLkM/JRCuy/86eaG6MgWYOB11Z3l9T+bK3xtBsyAGTADZsAMmAEzYAa2mIEvKPYvC7+/xX1w6HUG/qBe5BIzYAbMgBkwA2bADJgBM7D9DPAtpN8V/G2k7R/LQT24OsjaxmbADJgBM2AGzIAZMANmYHMZ+E6F9nvCn29uiI7sPBj4tvNwap9mwAyYATNgBsyAGTADZmANDHxRbb4i/PsBbe/I9qeFkfAn4Xwv1P+tAX5sagbMgBkwA2bADJgBM2AGzIAZWJiBn5CHfzLQy4nsxwJvdx6GuvF6oCubr4sBf/1sXcy7XTNgBsyAGTADZsAMmIFlM8Bfxvr6QKdHsh8JT4W3Q91rOn480I/N18iAH2rWSL6bNgNmwAyYATNgBsyAGVgqA98jb0MfahrVGQunSSR8/ezRUiOzMzNgBsyAGTADZsAMmAEzYAbMQAcDn1P50Aea6HKmk/g7GnRnwh1hHA183GwG/P/UbPb4dEX3vTLwGHax5HIzYAbMgBkwA2ZgCAO/IeP/O6TChth+XnF8Y45YRqrzmtCEumMd+WMDXxWmiT4U+7CJDHhDvImj0i+mmzL7D8J39zO3lRkwA2bADJgBM2AGejEwktXzXpabZXRL4fC7mKHC72eOBd7OIE8Evno2Efi9jWULGPB/TLQFg1QJ8R3p/5fwC5Vyq82AGTADZsAMmAEzMA8DbO7/bJ6Ka67zL9U++6KvrTkON28GzEBPBngY5cdsN3ra28wMmAEzYAbMgBkwAxeZAfZGvyxcv8iddN/qDPivn9W52eQSJiyvSmebHKRjMwNmwAyYATNgBszAihhgT/sdQvwK2YqadTObwoB/U7MpIzEsjj2Z891P/pMoixkwA2bADJgBM2AGLjsD3ycCfl1I90a8vYk/tUCf/uwiv4a/kq6L1238ml5Xn7ay3G9qtnLYPvOmwj7ZztAdtRkwA2bADJgBM2AGls4AfyTgw8zrR7r+0wAePuI5x/y6pkvrlM75kNliBszAHAzw1bPnQvppwxxuXCVhgK/y8T8IPxbeFbi2bC8DI4XOX6vhT3HG/xl6e3vjyLeRAdYQ1pKYg15TtnEUL3bMO+oe6+RXhLcuSFd/Tv3Yy/pyV9e8fYl4qPP49qZ2xEVexkuAN4QvCe8JMyH1y1+ktSyPgYuYn8tj5wJ5ihPqAnVp7V2ZKgImEBsPzvlkx5uQtQ/LXAGMwhgyfpw/EdhYWszAqhiI68hIDXLeCB+G81XF4HbMQBsD3O+mISc5nwk83Gy7PFYHRoVO8CYlfQBhH7Wo8NDDQ84s+D5c1KHrf4uBi5qfHuICA0zOLxT0Vs3HAJOHxW4vVGcTwrUXqPn4XHctxo2H0lEIhHFlPPlagsUMrIKB3ZBz49BYXGMOVtG42zADPRjgbUX64d29kLM3etTdVJMrCmwmcMyFb7hQFh9s6Psy36wcyx8+S23nsfi6m4HDwCf7MaR3fi7jNzX7avAoNLxpBybo6aYFtUA8TJjXBT71qwlJcCLQd8snDMBHbVM7U9mjhKizcP7ahpC3oziaDYllE8IYBT7iYpfHxNxgzsdxjMdXckNfL8TAgWqzMbqs8kQdZ26W5JmU5OAsFGKLbMqaEsLZ+oPXxvoQcv9vhNo6+Vhl6Tp5EXKU+fXNCiU8cKRvZ+Dl31Vs51Hvq9IHAutiXzmW4Z2+xhfMbqT+kHO1/Mzv40vLTwg/FBrhpEAqG8WnAk/Bmyr8J5XTTQ1uYFxMyq6NBIM/ZGINDGErzVngZwL52iUjGfBpzl6X4QrKiXcmEL/lLxjgO9LckK/0IGUimzOhtnj2cGGTjAHWl3iTuazk8LYcDvrc+1hLWFN2LitZ59DvuDb24f8cmt8Kl0P2PkfqEevkNssdBf+zHR2Ak/i2huODDvshxdxjuvZn0R8PNH1th8SwTbZryU+SBPIZ/JOMLRYTnn75TuGmS6MAl5m86+ovY5F+2pDHcSjFo1zp6xcMsBFue8MVaWp0Mo0Xaz6yaSJuy6cZIM+5EbcJNxnWqP02I5cNYoAHbDhlU3/ZhZty15pCDmJz77KTteT+z+TPa2M3qY1MuvY+O7KBT47bLOx/fqRHBxrZpA82q97Dsq+eCeyhL7twH3+vg4SYn+MOu97FbKJJgPtZDRLotLeX9RqStGfCNifRFcX/ROBYkrjZ4Gj5NAPwNhPaboQTlU8/XXUuDQvXInKgyrNFHFzwujfVP9YljiVhM9kIe6XCgToW1W2/4dPl0RL6cSwf04H8XVRz7ifcV9o2RXC1vwQCyOeLkIP0Y9E5yV7kyRI4vQwuuvY+jEcj3LoAZHxVffh8j37EeRsfbPiQZlV7w7gP4f5u+WTtZA19tULGueTnQzXG4KefzJEAJELbW4NKjGtRx0Tq+sRiLcH1bBT+2VDU5H0VnNYKrX/BAAvJM4F8yGU/lEf9vdxgwPVV2TYD7HPTmK/cvC11BuC4NieOVLYTqnKM53Vv9RLWjcN68daUsMFZpB88QOb3gq3p/DkFyv2xEUprylT6/dAuN+d4HlSDDouO3aDGztGYfjQL+IdnNkGs5ZZ+DDyRWWnvQ042Qlwb95Lzfp43x4q8+G2h738ovyvb9G3NyYq6clftkL+l9WJFIWxcM33zc6zIY65WO8Hmq00g/rbwsZC+Zr+jaybEqhKhLcY+ZSTvLwm8mtzWZNpX7I9aOvvDKjttKXfRJ/yMRAQLWir7uiDPeeDh+JZAfs8rnROvw/Etlb8meDzbiWJOk/f5nJ5Kx1gyhozn2+FcB8sCDOypbn4vWMDdhajKmkyO3ch6c6DrPxdmoZwctCzOAHuPVwSvjf25rO19JnLB2424TnLfm/V3u1GWn1M0fyz8v55RPZbdTyW2b+r8nZ51FzGL+zTWBssnDLCGlvbmR9Kn+ckaejYPabwRmAj7wnUB8vPNNNeNkMtIikNhIjwUCIrFHt004L6O+F1EeEM0EfCP73hD2dV5I1wRcqEOfeHTxm0T+jMTSv2iL4wZfeNTsJLEMb0VCuH/IGDRsSi1t2wdY0be3AmOWYTj+ZC2Io/pp1YjOfhIgL8UbODmlZiH89YnvrbJy9jBBzwg8HNPmIeT4GKlB/g5FGI+crwxRwTkO2NGfkeBh3wsF72BMB7Eu+0CX4v0o1F9UBJyEe7JzSiMazrOpXrr1pF3xAzifBoyj66qHvl1N+nITtDleThObIaeLjp2Q9s7L3v60Szg/D3VnbXUZxzTtZG1YZvWRrpGTsa5dD30dUhO5vSU9j4TGeX5ueg6mbe7yusfVGP/amCDV2T/JOMhvZcMdNdpTntw/E7FknE/FHZDOWPPuJML3OM3VfI5RtyxD31ijvfxtI/0ea78ZEGOwoJ+Ivwb4blAUI9DYRONdGRgXgs2ifrFKZ3hifdd4UcFnqw+FFjkf1cYC/x1Cv7sHrqhQowkIX+Kj04TCzramAjEfjvodXhJYl8o7yP4Hoo+fuexuaVKTwUGuSSRS7jJhbrwQl++LtwXePo9E0bCM+GGsKnyUIF9TSBe+vlIIGb6NVTg77nwxaQifln0mVgpmqHOl2hPfIw3Y5bLoRTjAHJ6Ivyk8A2B+RbzXKcbJyNFxFwlTvr3rjAVyMvrwlCJfb2dVDzReT6WXC8i5M1lF3KR+fdBhYip9NjEMWUc9oQnAusNm9FNE+YS+XhNIP+acL0/INA/ky25nObgTNelHMT/ZZdF59L3i0D4LQnjSY6yvpB/R+GctZG8RLfpEnPyYwVKTrLGkaPMpXml7zo5ZEPPXJ8H8/ahq97rMmCchwi5yL0frqOwt5znXtSnXXITYU3MhTZZJ4mJ/c5EmAroiY975B1hk4R1kznF/pIYyVH68E0h9rVPvOQ3kq6h+M3X0CH5+cIhRM+EdECf6hqSU2ckMroHQkliOTYz4WZiBAlnAmUfCUOTpwl1qf8DiV/ii34pu5qUxVN0bXGnVSAT26G4W2h3GSq4bvPNQkiscJ/LsRTwsxtsGGfGAYljhc0mCnExrmmeNLqmr/RnHnmoSs+EElfz+CvVIbamVNBDR1zMu1p9xg8b+gEP9xKftIuuLVcS85WeMoYsXidJq+jiHJtnPKhDfebHecqhnINtF9a1efsR189SfdaXR4Ec8pMxGSdkUQfdjUS37lNyhphuJYHEOXV/YHCN7ME8Ody3qUXGrm8bq7DbDVzN0xb8cj9gnHJhLYlr41TntbURHjdVYv6lOXkc+nKwQNBx7i5znWQdj2t33+NsgT50Vf15GaQfVnbZp+U82KR9gPPzEHKPdpgDubwjxV3hWrCZhfNo1+jkWbzYkCMxzQTmXpSnOsnX1aS4eLrU/MQZQrLzpHso8LCBxAX6Y53HJ6lUH8yKh+dBO9MxHQgWpPdDGYN3p1i7rGSi3w5Fpzr+amLGU+y0XO1bWojuKzwpw00J8FLSo+OJdYjAQZfQ3psCT8A1SZMqt2Fc4WccCu7pyDikwqdfcbxHOn9XmLxs0nlF/SHocnhXBv9IYKGPOUkd8hEhBxD6vi9MP7ns/Jf6o06r/ga1PuOhraytBcbjg4LBrnRPg565QF+OErs4hq8F3Z6OU+GJQP6MEtuu01rsNX2XP+LcEe4nhulYMj+Jbyo0wmPhjtAl8EGOL0O6+tZVXoqBPsM9+dwmD1U4bTMIPvCFzzapxRnzo1be5nMcCmP+pbasTyfCdYGxOBWaxCC2eyPRTXSe5m5SVDytxVzSFx0kyl2d/3PhWPgw0cc4iT/KPZ10xRljSKotdFrqU4ytrazW6DUVkDeTmkHQMzcZR+xrcksFzM03agaJvi3WtrI216+oMK4bqR1zogmKcbBJxy3yF/cQbW30KavFX9N3+YTPHxWOhTQnY19Puxy0lA/Z+7S4ealoT1e1fVBNf6Ov8znsuGf+2hz1qPKLwvtJXfYdPOgsW8bBYWkN/WGVpfOK3D1LAiCvRkLMY4qYq4xDH6nlZU3f5fOBDJhLh8JHwTjGRs4+SRxMdb6fXOenS89PApkJOH41aY1zdI+yCEhY9HSqJPhrgg3HdBCwpx7123xgl0tXPciNfomxJEPbLPlYpg5u3+hweFPl+RjkVShvSwzG4DTYpOOBb+qRgOiZSBNhFo469JI0h+IYdB1pq01mKsQHMUahHSY6fUH2hanQBKDrkphHtRzpqp+WT3XR1c9SedqnUntdeVqbm3zaE+uOdE58UVgAnwnXEl3tlE/eS3G36ahTkxvB30zHNP/I/bSvja5Hwcl+KNsN17UDdcAyZCYnbX0slVGnTWK+xYW/ZBt5wD/nNZmpIOWrZsd8LsXapsN3m8QY2+JjI0Ab5GEqcX1K605ksJfZ1S4bFbTFnpdNa46CPsZDvFHISzYbrC9pju7ruivO92VDDMuQafCV96ntmty62tJ4HBd81OzQxzYetPhqgh3HNpkGu7a4S2U3W5wyLtRpi4/62BxnfqjTVbel6U8VzYK/Uh9KuumnPLysGJKTHa6KxcTUtY8oVtwCJXnBmpfO26FhXw8+4tjNhjroYR9zsDYHcfGeQAy3En/0i3UJfVp3quudxK52GudEKS9rurs1Z9Kn8bya2HFeyrNJjzhnsjltaXNQEZsRAsmTonaDglTsGaCS0OEm2HDME+0wlLX5KPlN63GeS1peShriGNIm9kORx9R2HZOXY5u8o0LQJnGy5FzHOrHvTebkQNdwcpzpsZtkuq7LZXLFhCaumZD2KeZqnnvE2nQFGMq7uOrp5ltmpX6/EeIpldXGKDqkfCbkfUzjinPzfhYs4whvd4VJOI+L3m645thHarHX9G0+yV/iepgZxbGAr2vBZpLYsJDTp5oQC+vWac1goL7Wt0P5IdZaeVsz8N8IjEmb0M9pm0Hw0ejYdSOrxfn3VZe+1Mrbmr+pQsaQ3KtJXNPyG/Is1MXHPFKLt6Zva4M69AO8mhhyjm6ejd+p6s0EfC9DSv1aZOyYW/TrqCM45ueJMGqxYw1uhK58xkWpH8x16pfKuviLY8dcrAlxMY4HmQH96srfms+SvhZ/TV/yEXWxX8R3NTFcJCfT9vrw1hZfrazW1zZ9zdci+huqPM+8zduM+w7GgTxdtsTcTNedvA3uZ2cCHEaJcc0yfWLSedo2JqWyNodwA0enWTzcG9C/01a5UBbz87hQNlj1WdVgwUMIkICixBvnYylGAY2O0Sa1/Ytaw85mA8yfJrbjAfWiaZokXdUZtHe7jArl3BR4ldklJPftYMT3QOOg5vXQvyXcyQsGXu8Ge8Y4lXG4WEYyLSMfYmzXwwljnvqN8ZKT8wpfX1imlPoddaWyPm0/l1Hb94PHwUmTOCNX3hQ+FviqyWuhjEUSGRrLUPvQTPEQ15h0DhPv7WDNeNLefaFJPLC4x7qJ+qXT13XF96mXIW19pqytvNY+/I9rhYn+rR42fL21z1dca3FGfa28LYRZKITv0hrHeFJG/sWcowr3kdeED4RvCoznRJgJR0IfmSfeml/iRMjF9O3ZOOibcCTOe8KZ0BUn8TFnlyWl/i4ydvSBtaFL3u4yUPnXhXEPO0yW3Q98Mm6vtLR/O5Q1iQ33E/rPGH1VYGzfFU6FRtgXyNFH4VqHTin1rbNSxSDm5DdUnvodB/smHHd0pB9wgI78xJ64nwg1if6XGTNz4latwYqe+bZXKaup/6oK/rBWGPSv6wh3iwo8MVf+mfC1RZ0V6s+CjngfF8p52KGM8UzHajfYvh/0aR6cFPyUVMsc++ifnCvla+wbcb4lMM/a4oz5yfxcivDJC4EdZt5mumaAEZ682IhHoTPHyXV+2kiBzw8FFpQoBD8TKOOYluEfMiCiJNgSD3WZHGldziPBlF8tOMCGsoNCWUlFrENR8pPr8HkqEGPsz83cKFyT5E8F6rQJfaJv2JfkQSjfTQqxpQ4TKJdGikmuXOF1jO0wa5O4SuNLrJT1Ebjva9vHX8kGnhdpgwWAOGvjHnM9bZv5AzfM1ZJMpZyVClagi7Gl+XdN7RJvU2l/HMo51gR+8JHnSc1+Xj3+z7uNeWMbUu+NBfoB16xXrCUliWPRZIXv65ox4j6DTIU49jtBt8pD7EeTNco6mMZ5lMQ57ggQX6V1tKPaoOJFxm5QQ+dszBoAX/MKddvql9ZG1kTG9kuhUcZ2FHRTHW8k18FkpYfa3Mlzklj3BPY/nBM318+ENhm692nzFcuIeR708R1tvl0n0x4VDmXzD3vYtZnAJbzW1re2un3LbsmQPGQul4T8LN3PZtKT14wja+dUGAtd4y6TcxHiz+MkLuI5E8gLZCqMBWzbJObn/TajljLm81QghhdCABB2Es5pgIcRgiPIWI4+yrFOmuQ6PcWeMjoC8HVH2BUeBx2+0aUS7R9l+vTyli6oG/2OdY4f2oj1OV5NK4XzmDDx5lowWbmKvhLv3UrL6Gub1LTKzeCnNFkYj9NQzhgjjCVjDtJxDcUvxu8wXqzpSMzkC/FfE6YCXKFHl8pEF02mK11Sbya8Xypcom5XvpoF/DHmLLAleVXKmOv3gwE5jf1xqYJ0OwLzhuM6hByj/Rgv8zjO2QeVgMjNg0pZVNNvuCjlfUfVQcWHsgbbLvC0SD9Yr0BJ8B3zkvFFWL/QxXFkHu8LewL5sC55qIafCeQlwrwhTmK6EnT3dGS+oCfumlwNNrU8rtUbql907Ia2d172u3LcLOCc/GXsSpKujbSDlNZGxnYspGMbxzpUW/mhKyfJwf2AmY4xJ/d0znWbxLm5SXuftnhj2Zd18jtCnJO1Oicq+Bu1wh561gHuR6wD5yn040yo7eneUxk5SX7H8SUm6sQ1lfHeEY4E+r0OoR9PQ/ucR/6I/VEIiBjHwj3hSdDVDjE/OQ6Vm6pAu+Cl+iMpIIjGTwWSHxKfB92+jqnc1QVOrmZ6LulkE8o5YssR3xwZpBtCLtEOmzahLj6wI1aO++EYO1eK64FszoRNkshjTIQ8NvQ3c2XhGs5nQmmyUAYvjfBQiGMMHzXB9rBWuCL9NbXDODN5iOe+QD9KcU2CjQ6tApf4gPfzlF05bxZoIG7WS2N/R34jD7TxWGAeoC8JPDbCTqlwhbrICflHXjO29AN9LlMp9nNl4Zp8x8f1QtkyVeRcKe+W2cYqfL2xYD/gm4fnK4Vg4YexOBDiGsM43yrYTqVj/NclzImHwqnQCHFtId5UjnQxzXT5JZzS7/PeMC46dnnc67pmvjcLNB75frXggzWQsWA8aYONKmOKPpeJFE2ipA55uy6JOflBiKuWk1OVP0yCZB51zaUHsjlbV8fmbPdzqvcHAuP5l1t8sBb9psBxHqHeU6GZp/IcdchHUBLyj3FifxJjYmyvF4xn0t0p6FelGqmhE4E1lP6wVsa5l8Yw08VBqiicL5qfzAd4Yg59SvLEyK9jBUj+WPjSpzx8+qGm5qNQ9cXXpyBpHmlUCVLB1YIDkoTOb5LQX+ItbRQomwl9+SMxmkLn4k3gMJT18YefScHXOlQx3riBpT+5EGuTKwvXB9KxaJQWiYL53KrdnvHUGqDPM+F+weA96ciZW6GsbTyZ5FMhTnbi2iv4XKUqxtuoUfqRx0+8+0lALJw1oey4VrhE/aF8gW0X5s4i/bip+mnuRT4YQ9bXdDzzcY225GL0sbNmQokR7IaYWGNSYa2gbJTp00vuKc+FWn9bqg4qWnTsBjV2jsbw2SzgH55nwt2Cj2PpyK0boaxtTBrZTBIfT3TOekt+gnUJMYM7An3Jc3Im3X4SHDm6J4wSXX5K397PlRt+/eOKj/6DL7TE+h0q+08t5V1F5Az8nPeeIMZB3tb2e/T1UTCMeVCKn/Fm3JGdksEKdXGOHarNfKyIjTivCaOWmOCfcVi7PKgEQicbgQ5yjJ3uE/CBjPJJ3KceNrQVJ8HVrBI3BMi90dfZiuzgJm4GiDEVkp8NbF/hIShd0GO9mGy7fR3JrhGot0nCZKd/pXyaSN90BEu9mbCKfjGJ9zri6Spm/PmkMRcWAHK5xENqSwzUPxImwrvCY2EsrFuInbE8zQLZ1/VXhYlAvD8XzjOzF5c3hVK+l2wX1e3IAdh2GS2hH8fyAVJhQ1Aaz8zsxeW+MAsF03Bc94EHE+JPN09jXc9CYNNKgPSbDcpBpXyZaubzeJkO1+SLfuwt2DZrI2tZKqwpz4VZpq9dMt7jUEhMXI8E1kuu1y2lnCQ+4ozxjcM1sU75pyDsK1a1Thaan0vFXuZXhF8Isb/V4uUfqGzePxTD/upMuNHif9lF5OlMIIdTuaMLxqnP/ncqO/J0R7j3kpf1XTxR03BJ/6JMdDIVRgLnJdmo/GRBpxO3kkhJjkPhmcAAceS6T9LgD2I4DhFIfCDENmmXNncTJ6dBN8TvqmyJnZjzB5hj6dKbbJ948EG9KCQMG1v8j4WucZjIBjTCSThn4qxTaH8s0Af6wvm1EBBlRwKxNsIkIBS/dICLmRDrlmw2TfdEAX0pBEXce0Lkgfxu68u9YIt9inX3kbjfDjFNdRyHgHayOGPM+6E8P5Dn01zp63Nn4KZaOBPiWsIxjudXdD7uiGCkcvL6SOB8nUL7Y+GZkK+RlMU4yc2SsAFpSgXWnTsDjA1rOkIO7gnp2hiKigfGkxxOBX8TYT/Tr/pypAbHQpqT6BD0TTjnMBJmwlSo5egjlR0K2yQ/qWB/RPgJgTH9mZbgf0xl/7ilvFZ0VwXkwNA9Vs0fevau3Je6hHv6LDFiD82HefSVtTTdU5d8keuNcFQqXLGOvHtTSOfetRBDGmfU5eFtXH6SEKdCfBBhMJoCugaJju4Lu5wMlCuybwTiiOD6IPjhxvMknG/iAQ5JCGKkLwjH9Dqoex1IkjsCnNc46eVoQ4xOFEcTQH84ZyINEfLzudAnD4f4PW/bGyFu4iefY//n5eG84+3yz7g1hX501cvLuSkwP+DFsnoG2Ew2odkjHfN1ZvURzdcisdOPNP74IUKXR9btmbBta0pXv7alHN7jGnA/jGGjY8RoWzqSxblITuZd3vS9Tx5vvP5r4SRulv9jzVD6fyswF4cI6xd7rvhQPKRum+2hCkEfeS/YXtExXX84Jwe2RRoFmmPUM3geLJnD13rar8zsQC1NVtbasIZubCppSTdI6jOBSXYz6LmxkvTzCAnSCKOkMm1cZjlR53e2lABu3s2Wxn4eYY8CHxu3EJ5HZzfYJzekbbr5dlHJGjlknWxkv61rShcX21LO2sjaflFlaE6mPGzD3qdr3PiLZuyL/odQmpvofl34S12OknIegD4SWL+WKfgjVnjvK1MZ7gXjUv/6+tlGO3hqBN/Ht3H0esR8LBsmRJxoXC/7U4QeYdjEDJgBM2AGzIAZMANrZ4CN/v8W2Bv9lUI0PMw8Ffo+EPBmnweaBwVf86r4IHoqEOOjeZ24nhm4aAzEp3wmBRN0Fo4XrZ/ujxkwA2bADJgBM2AGuhhgL8QfDOCB4YcKxn9XumlBX1LxQPOhwAfG8SEofRhKdZxH4Cstu6prPnC+J/CWkNgi4ofS1LGsiYHPrqldN/syA0yOfy18UWDCnApMFIsZMANmwAyYATNgBi4bA+yB/pvwA8LfEf5LRgBfJeNNTZfwUMIei6+LngmPBXyjj/useB4fYKLPaPdKqB/1+fFjKfixv8UMmIHAwBMdmUAc+U2NxQyYATNgBsyAGTADl5WBL6vj7IucHgTvAAAEA0lEQVSmBQL+hXTjgj5XHQcf+Dkv0IZlAxjwm5oNGIQQwi/p+LowEvzEvznj4kjMgBkwA2bADJiB1TPAHwJA2Bvlb1Z4U8OfdO4SvioWHzrim5dYJ7/u8lUr/2atwHozcFkZYIIywfxjs8uaAe63GTADZsAMmAEzEBn4bp2wL/oTIf1qGOd8NS3/upiZMwNmYIMY4Pue/rHZBg2IQzEDZsAMmAEzYAbWwgAPLf9T4MHmrycR/G2d8zsZixl4iQH+koNlcxi4r1B+cXPCcSRmwAyYATNgBsyAGVgbA/GPAfAgE4Uf/fP743mF+ovKaFEHrr98BvxQs3xOF/H4FVXmbY3FDJgBM2AGzIAZMAOXmQHe0MTf1XxvQsQtnX9jTmJ4oOHPO8/zYHNN9e4J7NWeCf7625yDcF7V/FBzXszarxkwA2bADJgBM2AGzMAiDPxaqPy3Eief1zkPJvMIb3h4KJr3TQ9vjvzb53mYdx0zYAbMgBkwA2bADJgBM3BJGbitfvPGhv+Ikzcj4Hk4rouScYjJb2rWNQKVdv2mpkKM1WbADJgBM2AGzIAZMANrZSB+/exvhii+S0e++jWPTFWpEfbmqew6m8+A/5+azR8jR2gGzIAZMANmwAyYgcvIwB+p078vfKcwEvhtzdcF3t4MkQMZPxTeEnioOQmVmx5OsD0q2A2NoeDCqmUy4IeaZbJpX2bADJgBM2AGzIAZMAPLYoAHh98QeKj5PoHfw8zze5qPQr3HOu4LUcbJ+dBTvn7mB5uhrJ2jvb9+do7k2rUZMANmwAyYATNgBszAQgz8Zqj9uo7fL/zqHN542xK/dhbf0kQ38bc6teMczbnKOhjwm5p1sO42zYAZMANmwAyYATNgBvowEH9Xw/9V8z3Cb/WpVLDZl+5Y2BFGAg83hwW7XMVveKa50tdmwAyYATNgBsyAGTADZsAMmIG+DPw9GfI1r98R/mvfSgW7M+nGwlS4Vijvo6L+2wLx3A7oU882K2DAXz9bAcluwgyYATNgBsyAGTADZmAuBuL/VXNTtef9TzdpeF+4JxwJPODMI2NVui7whucNYXceJ65jBsyAGTADZsAMmAEzYAbMwOVigN+6/HeBtyP/9HJ13b0dwoDf1Axhy7ZmwAyYATNgBsyAGTADq2SAh5nfDg3y55wtZqDIgB9qirRYaQbMgBkwA2bADJgBM7AhDDwNcfzKhsTjMDaQAT/UbOCgOCQzYAbMgBkwA2bADJiBbzHwyzrjgcb/L4yTosrAt1VLXGAGzIAZMANmwAyYATNgBtbPwP9RCPy25j+vPxRHYAbMgBkwA2bADJgBM2AGzIAZMANmwAyYATNgBsyAGTADZsAMmAEzYAbMwMsM/H8ouJdWva4GwAAAAABJRU5ErkJggg=="
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To assess the degree similarity between critics given their respective preferences, we can use the euclidian distance.\n",
    "Its formula for an N-dimensional space is is: ![image.png](attachment:image.png)\n",
    "Because we want a smaller distance to indicate a larger similarity, we will use 1/d(p,q) as our similarity value:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1336,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import sqrt\n",
    "\n",
    "\n",
    "def sim_distance(p1, p2, show_common_dims=False, prefs=critics):\n",
    "    '''\n",
    "    Returns a distance-based similarity score between two critics.\n",
    "    '''\n",
    "\n",
    "    # Get the list of shared_items\n",
    "    common_items = []\n",
    "    for movie in prefs[p1]:\n",
    "        if movie in prefs[p2]:\n",
    "            common_items.append(movie)\n",
    "    # If they have no ratings in common, return 0\n",
    "    if len(common_items) == 0:\n",
    "        return 0\n",
    "    if show_common_dims:\n",
    "        print(\"common dimensions between {} and {}: \".format(p1, p2) + str(len(common_items)))\n",
    "    # Add up the squares of all the differences\n",
    "    sum_of_squares = sum([pow(prefs[p1][movie] - prefs[p2][movie], 2) for movie in common_items])\n",
    "\n",
    "    # return sqrt(sum_of_squares)\n",
    "    return 1 / sqrt(sum_of_squares)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using this simple formula, you can calculate a similarity between two critics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1337,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "common dimensions between Lisa Rose and Gene Seymour: 6\n"
     ]
    },
    {
     "data": {
      "text/plain": "0.41702882811414954"
     },
     "execution_count": 1337,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get the distance between 'Lisa Rose' and 'Gene Seymour'\n",
    "sim_distance('Lisa Rose', 'Gene Seymour', True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try this with other names so you can see who is closer or further."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Name at least two problems with the sim_distance function as it is defined above. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Problems:\n",
    "1. first problem is what funciton returns. Imagine the distance of 2 person is 0. we can not perform division to 0. Our suggestion is to change result as follows:\n",
    "    return 1 / (1 + sqrt(sum_of_squares))\n",
    "2. Second problem is existence of \"sqrt\". If the sum_of_squares is between 0 and 1, the sqrt increases the distance unwillingly. So it is better to remove the sqrt. So the final result would be:\n",
    "    1/ (1 + sum_of_squares)\n",
    "    "
   ]
  },
  {
   "attachments": {
    "image.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A different measure of similarity can be given by pearson correlation.\n",
    "Which follows: ![image.png](attachment:image.png)\n",
    "\n",
    "Where the dividend represents a measure of covariance between dimensions, whereas the divisor is the product of the standard deviation of the scores given by each user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1338,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sim_pearson(p1, p2, prefs=critics, verbose=False):\n",
    "    '''\n",
    "    Returns the Pearson correlation coefficient for p1 and p2.\n",
    "    '''\n",
    "\n",
    "    '''Step 1: Get the list of mutually rated items'''\n",
    "    common_items = []\n",
    "    dic = {}\n",
    "    for movie in prefs[p1]:\n",
    "        if movie in prefs[p2]:\n",
    "            common_items.append(movie)\n",
    "    # If they are no ratings in common, return 0\n",
    "    if len(common_items) == 0:\n",
    "        return 0\n",
    "    '''Step 2: Sum calculations'''\n",
    "    n_common_items = len(common_items)\n",
    "    sum1 = sum([prefs[p1][movie] for movie in common_items])\n",
    "    sum2 = sum([prefs[p2][movie] for movie in common_items])\n",
    "    # Sums of squares\n",
    "    sum1Sq = sum([pow(prefs[p1][movie], 2) for movie in common_items])\n",
    "    sum2Sq = sum([pow(prefs[p2][movie], 2) for movie in common_items])\n",
    "    # Sum of the products\n",
    "    pSum = sum([prefs[p1][movie] * prefs[p2][movie] for movie in common_items])\n",
    "    # Calculate r (Pearson score)\n",
    "    num = pSum - sum1 * sum2 / n_common_items\n",
    "    den = sqrt((sum1Sq - pow(sum1, 2) / n_common_items) * (sum2Sq - pow(sum2, 2) / n_common_items))\n",
    "    if den == 0:\n",
    "        return 0\n",
    "    r = num / den\n",
    "    if verbose:\n",
    "        print(\"common dimensions: %s\" % len(common_items))\n",
    "        print(\"Similarity Score for {} and {}: {}\".format(p1, p2, r))\n",
    "    return r\n",
    "\n",
    "\n",
    "#for k in critics.keys():\n",
    "#    sim_pearson('Michael Phillips', k, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try the examples you used for the eucledian distance again, but now using the pearson correlation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1339,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "0.39605901719066977"
     },
     "execution_count": 1339,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sim_pearson('Lisa Rose', 'Gene Seymour')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ranking critics on similarity\n",
    "The topMatches function below calculates all similarities of a given critic with his peers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1340,
   "metadata": {},
   "outputs": [],
   "source": [
    "def topMatches(person, n=5, similarity=sim_pearson, prefs=critics):\n",
    "    '''\n",
    "    Returns the best matches for person from the prefs dictionary. \n",
    "    Number of results and similarity function are optional params.\n",
    "    '''\n",
    "    if similarity not in [sim_distance, sim_pearson]:\n",
    "        # NB: here we are comparing FUNCTION DEFINITION.\n",
    "        # We do that only in a jupyter notebook for the sake of simplicity.\n",
    "        raise ValueError(\"Callback functions should be: 'sim_pearson' or 'sim_distance'.\")\n",
    "\n",
    "    scores = [(similarity(person, other, prefs=prefs), other) for other in prefs\n",
    "              if other != person]\n",
    "    scores.sort()\n",
    "    scores.reverse()\n",
    "    return scores[0:n]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So you can now get the 3 critics closest to Toby by calling:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1341,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "[(0.9912407071619299, 'Lisa Rose'),\n (0.9244734516419049, 'Mick LaSalle'),\n (0.8934051474415647, 'Claudia Puig')]"
     },
     "execution_count": 1341,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topMatches('Toby', n=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*****************************************************\n",
    "### Task: Effect of similarity function used\n",
    "Call the topMatches function on a number of critics with both the default sim_pearson, but also with the sim_distance function. Would you have preference of one over the other? \n",
    "*****************************************************"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b style=\"color: red\">Answer:</b>\n",
    "the Euclidean distance or Euclidean metric is the \"ordinary\" straight-line distance between two points in Euclidean space while Pearson Correlation measures the similarity in shape between two profiles.\n",
    "\n",
    "The pearson considers which movie is the most favorable to a user. for example if 3 movies A B C are respectively most favorable movies of user1, and A B C also in same order are respectively the most favorable movies of user2, These 2 users have pearson similarity of 1. while in the Euclidean similarity only simple linear distance is calculated.\n",
    "\n",
    "So based on the our research and trying the topMatch function, we prefer the pearson similarity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Exercise 2: Recommending Items**\n",
    "\n",
    "One way to recommend movies to a person would be to rate the movies she has not seen yet by using the scores of the others weighted by the similarity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1342,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getRecommendations(person, similarity=sim_pearson, prefs=critics):\n",
    "    '''\n",
    "    Gets recommendations for a person by using a weighted average\n",
    "    of every other user's rankings\n",
    "    '''\n",
    "    if similarity not in [sim_distance, sim_pearson]:\n",
    "        raise ValueError(\"Callback functions should be: 'sim_pearson' or 'sim_distance'.\")\n",
    "\n",
    "    totals = {}\n",
    "    simSums = {}\n",
    "    for other in prefs:\n",
    "        # Don't compare me to myself\n",
    "        if other == person:\n",
    "            continue\n",
    "        sim = similarity(person, other, prefs=prefs)\n",
    "        # Ignore scores of zero or lower\n",
    "        if sim <= 0:\n",
    "            continue\n",
    "        for item in prefs[other]:\n",
    "            # Only score movies I haven't seen yet\n",
    "            if item not in prefs[person] or prefs[person][item] == 0:\n",
    "                # Similarity * Score\n",
    "                totals.setdefault(item, 0)\n",
    "                # The final score is calculated by multiplying each item by the\n",
    "                #   similarity and adding these products together\n",
    "                totals[item] += prefs[other][item] * sim\n",
    "                # Sum of similarities\n",
    "                simSums.setdefault(item, 0)\n",
    "                simSums[item] += sim\n",
    "    # Create the normalized list\n",
    "    rankings = [(total / simSums[item], item) for (item, total) in\n",
    "                totals.items()]\n",
    "    # Return the sorted list\n",
    "    rankings.sort()\n",
    "    rankings.reverse()\n",
    "    return rankings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1343,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "[(3.4721701369256524, 'The Night Listener'),\n (2.7709066207646793, 'Lady in the Water'),\n (2.4349456273856207, 'Just My Luck')]"
     },
     "execution_count": 1343,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "getRecommendations('Toby', similarity=sim_distance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1344,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "[(3.3477895267131017, 'The Night Listener'),\n (2.8325499182641614, 'Lady in the Water'),\n (2.530980703765565, 'Just My Luck')]"
     },
     "execution_count": 1344,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "getRecommendations('Toby')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the output does not only consist of a movie title, but also a guess at what the user's rating for each movie would be.\n",
    "\n",
    "*****************************************************\n",
    "### Task: Explainable recommendations\n",
    "Can you also find out how to give information on how the recommendation is built up. For example about the 'closest' person that also watched this movie?\n",
    "*****************************************************"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1345,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "[(3.3477895267131017,\n  'The Night Listener',\n  ['Lisa Rose', 'Gene Seymour', 'Mick LaSalle', 'Jack Matthews']),\n (2.8325499182641614,\n  'Lady in the Water',\n  ['Gene Seymour', 'Mick LaSalle', 'Jack Matthews']),\n (2.530980703765565, 'Just My Luck', ['Lisa Rose', 'Claudia Puig'])]"
     },
     "execution_count": 1345,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# so based on what we understood of this task we need to write a function\n",
    "# that not only returns score and movie, but also more information like closest people that also watched that movie\n",
    "\n",
    "def getCompleteRecommendation(person, similarity=sim_pearson, prefs=critics):\n",
    "    '''\n",
    "    Gets recommendations for a person by using a weighted average\n",
    "    of every other user's rankings\n",
    "    '''\n",
    "    if similarity not in [sim_distance, sim_pearson]:\n",
    "        raise ValueError(\"Callback functions should be: 'sim_pearson' or 'sim_distance'.\")\n",
    "\n",
    "    totals = {}\n",
    "    simSums = {}\n",
    "    for other in prefs:\n",
    "        # Don't compare me to myself\n",
    "        if other == person:\n",
    "            continue\n",
    "        sim = similarity(person, other, prefs=prefs)\n",
    "        # Ignore scores of zero or lower\n",
    "        if sim <= 0:\n",
    "            continue\n",
    "\n",
    "        closest_person = ''\n",
    "        for item in prefs[other]:\n",
    "            # Only score movies I haven't seen yet\n",
    "            if item not in prefs[person] or prefs[person][item] == 0:\n",
    "                # Similarity * Score\n",
    "                totals.setdefault(item, 0)\n",
    "                # The final score is calculated by multiplying each item by the\n",
    "                #   similarity and adding these products together\n",
    "                totals[item] += prefs[other][item] * sim\n",
    "                # Sum of similarities\n",
    "                simSums.setdefault(item, 0)\n",
    "                simSums[item] += sim\n",
    "\n",
    "    # Create the normalized list\n",
    "    rankings = [(total / simSums[item], item, close_person(person, item, total / simSums[item])) for (item, total) in\n",
    "                totals.items()]\n",
    "\n",
    "\n",
    "    # Return the sorted list\n",
    "    rankings.sort()\n",
    "    rankings.reverse()\n",
    "    return rankings\n",
    "\n",
    "def close_person(person, movie_name, person_score, prefs=critics):\n",
    "    storage = {}\n",
    "    for other in prefs:\n",
    "        if other == person:\n",
    "            continue\n",
    "        for movie in prefs[other]:\n",
    "            if movie == movie_name:\n",
    "                diff = abs(person_score - prefs[other][movie]);\n",
    "                # there could be multiple people with minimum difference in score\n",
    "                if diff not in storage:\n",
    "                    storage[diff] = []\n",
    "                storage[diff].append(other)\n",
    "    minimum_diff = min(storage.keys())\n",
    "    return storage[minimum_diff]\n",
    "\n",
    "getCompleteRecommendation('Toby')\n",
    "\n",
    "# above line returns movies that Toby did not rate and also closest people related to each movie to toby. (those people have exact same closeness to toby in specified movie)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### **Exercise 3: Transformations** \n",
    "**You have been building recommendations based on similar users in Exercise 2, but you could of course also build recommendations based on similar items. In this exercise you will do this.** \n",
    "\n",
    "The function is essentially the same, but you need to transfer your data, from:\n",
    "\n",
    "<code>{'Lisa Rose': {'Lady in the Water': 2.5, 'Snakes on a Plane': 3.5},\n",
    "'Gene Seymour': {'Lady in the Water': 3.0, 'Snakes on a Plane': 3.5}}</code>\n",
    "\n",
    "to\n",
    "\n",
    "<code>{'Lady in the Water': {'Lisa Rose': 2.5,'Gene Seymour': 3.0},\n",
    "'Snakes on a Plane': {'Lisa Rose': 3.5,'Gene Seymour': 3.5}}</code>\n",
    "\n",
    "This is what the transformPrefs function does. \n",
    "\n",
    "You can now create a dictionary for movies with their scores assigned by different people by invoking:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1346,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transformPrefs(prefs=critics):\n",
    "    '''\n",
    "    Transform the recommendations into a mapping where persons are described\n",
    "    with interest scores for a given title e.g. {title: person} instead of\n",
    "    {person: title}.\n",
    "    '''\n",
    "    result = {}\n",
    "    for person in prefs:\n",
    "        for item in prefs[person]:\n",
    "            result.setdefault(item, {})\n",
    "            # Flip item and person\n",
    "            result[item][person] = prefs[person][item]\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1347,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Lady in the Water': {'Lisa Rose': 2.5, 'Gene Seymour': 3.0, 'Michael Phillips': 2.5, 'Mick LaSalle': 3.0, 'Jack Matthews': 3.0}, 'Snakes on a Plane': {'Lisa Rose': 3.5, 'Gene Seymour': 3.5, 'Michael Phillips': 3.0, 'Claudia Puig': 3.5, 'Mick LaSalle': 4.0, 'Jack Matthews': 4.0, 'Toby': 4.5}, 'Just My Luck': {'Lisa Rose': 3.0, 'Gene Seymour': 1.5, 'Claudia Puig': 3.0, 'Mick LaSalle': 2.0}, 'Superman Returns': {'Lisa Rose': 3.5, 'Gene Seymour': 5.0, 'Michael Phillips': 3.5, 'Claudia Puig': 4.0, 'Mick LaSalle': 3.0, 'Jack Matthews': 5.0, 'Toby': 4.0}, 'You, Me and Dupree': {'Lisa Rose': 2.5, 'Gene Seymour': 3.5, 'Claudia Puig': 2.5, 'Mick LaSalle': 2.0, 'Jack Matthews': 3.5, 'Toby': 1.0}, 'The Night Listener': {'Lisa Rose': 3.0, 'Gene Seymour': 3.0, 'Michael Phillips': 4.0, 'Claudia Puig': 4.5, 'Mick LaSalle': 3.0, 'Jack Matthews': 3.0}}\n"
     ]
    }
   ],
   "source": [
    "movies = transformPrefs()\n",
    "print(movies)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And find similar items for a particular movie like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1348,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "[(0.6579516949597695, 'You, Me and Dupree'),\n (0.4879500364742689, 'Lady in the Water'),\n (0.11180339887498941, 'Snakes on a Plane'),\n (-0.1798471947990544, 'The Night Listener'),\n (-0.42289003161103106, 'Just My Luck')]"
     },
     "execution_count": 1348,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topMatches('Superman Returns', prefs=movies)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or find people who may like a particular movie:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1349,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "[(4.0, 'Michael Phillips'), (3.0, 'Jack Matthews')]"
     },
     "execution_count": 1349,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "getRecommendations('Just My Luck', prefs=movies)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*****************************************************\n",
    "#### Task: why does the example above work?\n",
    "Try to follow exactly what is going on in the last call. Notice that Michael and Jack did not rate 'Just my Luck'. How is their rating for it built up?\n",
    "*****************************************************"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "<b style=\"color: red\">Answer:</b>\n",
    "In the last task, We were recommending movies to people who did not watch them and tried to predict what would be their rating for those movies.\n",
    "But in this task we transformed the dictionary and basically exchanged movies and people. So we are now recommending the audience for a specific movie and predict their ratings for that movie.\n",
    "\n",
    "So the code works because we simply just exchanged people and movies. And lack of movie in dictionary of specific person in last assignment is the same as lack of person in dictionary of movies in this task. And both means that the user did not rate the movie.\n",
    "\n",
    "for example: for micheal and movie called 'Just my Luck' we have following dictionaries:\n",
    "\n",
    "<code>'Michael Phillips': {\n",
    "        'Lady in the Water': 2.5,\n",
    "        'Snakes on a Plane': 3.0,\n",
    "        'Superman Returns': 3.5,\n",
    "        'The Night Listener': 4.0,\n",
    "    }</code>\n",
    "\n",
    "and transformed one is:\n",
    "\n",
    "<code>\"Just My Luck\":{\n",
    "      \"Lisa Rose\":3.0,\n",
    "      \"Gene Seymour\":1.5,\n",
    "      \"Claudia Puig\":3.0,\n",
    "      \"Mick LaSalle\":2.0\n",
    "   }</code>\n",
    "\n",
    "so in first case \"Just My Luck\" movie does not exist in list of movies that Michael watched. In the second case, Michael is not in the list of people that saw movie \"Just My Luck\".\n",
    "\n",
    "So the result of this excersise ([(4.0, 'Michael Phillips'), (3.0, 'Jack Matthews')]) predicts that Michael will rate \"Just My Luck\" with score of 4."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Exercise 4: Sentence Similarity**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1350,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import natural language processing software we need later.\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1351,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/alirezasoltaninezhad/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/alirezasoltaninezhad/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": "True"
     },
     "execution_count": 1351,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Download wordnet and punkt sentence tokenizer\n",
    "nltk.download('wordnet')\n",
    "nltk.download('punkt')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below we have some example sentences to compare later on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1352,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies = [\"I saw a really good movie last night.\",\n",
    "          \"The movie is based on the director's life.\",\n",
    "          \"The movie starts at ten.\",\n",
    "          \"I took her to a movie.\",\n",
    "          \"The movie stars Al Pacino.\",\n",
    "          \"The movie opened last weekend.\",\n",
    "          \"The movie lasted two hours.\",\n",
    "          \"He directed several movies.\",\n",
    "          \"We just shot another movie.\",\n",
    "          \"The movie was set in New York.\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1353,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_jaccard_sim(str1, str2):\n",
    "    a = set(str1.split())\n",
    "    b = set(str2.split())\n",
    "    c = a.intersection(b)\n",
    "    return float(len(c)) / (len(a) + len(b) - len(c))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1354,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare(s1, s2):\n",
    "    #Import a Lemmatizer to get the root form of certain words\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "    #Tokenize both sentences to get each word separately\n",
    "    word_list1 = nltk.word_tokenize(s1)\n",
    "    word_list2 = nltk.word_tokenize(s2)\n",
    "\n",
    "    #     print(\"Tokenized sentence\", word_list1) #Uncomment to see an example of the tokenized sentence\n",
    "\n",
    "    #Lemmatize both sentences\n",
    "    lemmatized_output1 = ' '.join([lemmatizer.lemmatize(w, 'v') for w in word_list1])\n",
    "    lemmatized_output2 = ' '.join([lemmatizer.lemmatize(w, 'v') for w in word_list2])\n",
    "\n",
    "    return lemmatized_output1, lemmatized_output2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1355,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence 1: I saw a really good movie last night . \n",
      " Sentence 2: I saw a really good movie last night . \n",
      " Similarity Score: 1.0\n",
      "Sentence 1: I saw a really good movie last night . \n",
      " Sentence 2: The movie be base on the director 's life . \n",
      " Similarity Score: 0.11764705882352941\n",
      "Sentence 1: I saw a really good movie last night . \n",
      " Sentence 2: The movie start at ten . \n",
      " Similarity Score: 0.15384615384615385\n",
      "Sentence 1: I saw a really good movie last night . \n",
      " Sentence 2: I take her to a movie . \n",
      " Similarity Score: 0.3333333333333333\n",
      "Sentence 1: I saw a really good movie last night . \n",
      " Sentence 2: The movie star Al Pacino . \n",
      " Similarity Score: 0.15384615384615385\n",
      "Sentence 1: I saw a really good movie last night . \n",
      " Sentence 2: The movie open last weekend . \n",
      " Similarity Score: 0.25\n",
      "Sentence 1: I saw a really good movie last night . \n",
      " Sentence 2: The movie last two hours . \n",
      " Similarity Score: 0.25\n",
      "Sentence 1: I saw a really good movie last night . \n",
      " Sentence 2: He direct several movies . \n",
      " Similarity Score: 0.07692307692307693\n",
      "Sentence 1: I saw a really good movie last night . \n",
      " Sentence 2: We just shoot another movie . \n",
      " Similarity Score: 0.15384615384615385\n",
      "Sentence 1: I saw a really good movie last night . \n",
      " Sentence 2: The movie be set in New York . \n",
      " Similarity Score: 0.13333333333333333\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "for x in range(len(movies)):\n",
    "    l1, l2 = compare(movies[0], movies[x])\n",
    "    print(\"Sentence 1:\", l1, '\\n', \"Sentence 2:\", l2, '\\n', \"Similarity Score:\", get_jaccard_sim(l1, l2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*****************************************************\n",
    "#### Task: In what scenario's could the Jaccard Similarity be more useful than the Euclidean distance and the Pearson Similarity metrics? Why is that? \n",
    "*****************************************************"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "<b style=\"color: red\">Answer:</b>\n",
    "The Jaccard similarity function compares two binary vectors (sets). Jaccard similarity is a widely used metric for determining text similarity. Calculating the Jaccard similarity is more computationally expensive because it compares all of the terms in one document to others. The Jaccard similarity proves useful in detecting duplicates. Euclidean distance is less commonly used in natural language processing (NLP) than Jaccard similarity. It is appropriate for continuous numerical variables. Because the Euclidean distance is not scale invariant, the data should be scaled before computing the distance. The redundant information impact in the dataset is also multiplied by Euclidean distance. We would weigh the redundancy effect n times if I had n highly correlated variables and used all variables as input. WordNetLemmatizer is used to normalize speech parts in sentences, reducing the effects of redundant vocabulary. For example, be can be used instead of am/is/are to find more relevant sentences. The distance between two data vectors that have no attribute values in common may be smaller than the distance between another pair of data vectors that have the same attribute values. Although WordNetLemmatizer reduce precision, it increases recall."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Exercise 5: Building a Reddit Recommender**\n",
    "\n",
    "After having created your Reddit account, go to User Settings -> Safety & Privacy -> Manage third-party app authorization.\n",
    "Here, you will create your own app. Give it a name, and add \"https://www.reddit.com/prefs/apps/\" to the redirect uri. Keep the other settings as they are.\n",
    "\n",
    "* replace the '???' in the user_agent string with your name (or any unique string).\n",
    "* replace the '???' in the client_id with the id right underneath your web app name.\n",
    "* replace the '???' in the client_secret with the key next to 'secret'.\n",
    "\n",
    "NOTE: install praw v. 3.5 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1356,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "import praw\n",
    "import time\n",
    "\n",
    "#Delete keys before handing in the notebook\n",
    "r = praw.Reddit(user_agent='behnam', client_id='FUF106C4ntH8mTYHzyA17Q',\n",
    "                client_secret='s0Bcm8lVyKA8nkHsm45bfVV_LEiv6Q',\n",
    "                redirect_url='https://www.reddit.com/prefs/apps/'\n",
    "                             'authorize_callback')\n",
    "\n",
    "\n",
    "def initializeUserDict(subreddit, count=10):\n",
    "    user_dict = {}\n",
    "    # get the top count' popular posts\n",
    "    for post in r.subreddit(subreddit).top(limit=count):\n",
    "        # find all users who commented in this\n",
    "        flat_comments = post.comments.list()\n",
    "        for comment in flat_comments:\n",
    "            try:\n",
    "                user = comment.author.name\n",
    "                user_dict[user] = {}\n",
    "            except AttributeError:\n",
    "                pass\n",
    "    return user_dict\n",
    "\n",
    "\n",
    "def fillItems(user_dict, count=100):\n",
    "    all_items = {}\n",
    "    # Find links posted by all users\n",
    "    for user in user_dict:\n",
    "        # print(\"finding subreddits where user \" + user + \"has commented\")\n",
    "        # find new comments for given user\n",
    "        comments = r.redditor(user).comments.new(limit=count)\n",
    "        for c in comments:\n",
    "            # Get the subreddit where the comment was made\n",
    "            subreddit = c.subreddit\n",
    "            sub_name = subreddit.display_name\n",
    "            # print(sub_name)\n",
    "            if sub_name in user_dict[user]:\n",
    "                user_dict[user][sub_name] += 1.0\n",
    "            else:\n",
    "                user_dict[user][sub_name] = 1.0\n",
    "\n",
    "            all_items[sub_name] = 1\n",
    "    #     Fill in missing items with 0\n",
    "    #     for subr_counts in user_dict.values():\n",
    "    #         for item in all_items:\n",
    "    #             if item not in subr_counts:\n",
    "    #                 subr_counts[item]=0.0\n",
    "\n",
    "    return user_dict\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can get a list of popular recent posts about programming from the programming subreddit (https://www.reddit.com/r/VUAmsterdam) by invoking the code below.  Don't forget to replace the '???' in the user_agent string with your name (or any unique string)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1357,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "praw version == 7.5.0\n",
      "\n",
      " * Theres a reason that programmers always want to throw away old code and start over: they think the old code is a mess. They are probably wrong. The reason that they think the old code is a mess is because of a cardinal, fundamental law of programming: Its harder to read code than to write it.\n",
      "\n",
      " * YouTube page load is 5x slower in Firefox and Edge than in Chrome because YouTube's Polymer redesign relies on the deprecated Shadow DOM v0 API only implemented in Chrome.\n",
      "\n",
      " * How I Got Paid $0 From the Uber Security Bug Bounty\n",
      "\n",
      " * Google wins trial against Oracle as jury finds Android is fair use\n",
      "\n",
      " * TIL there's a community called \"dwitter\" where people compose 140 character JavaScript programs that produce interesting visuals\n",
      "\n",
      " * Eye tracking software for sufferers of ALS/MND can cost tens of thousands of dollars, so I've spent 3.5 years of my spare time writing a free & open-source alternative - meet OptiKey (C#, Rx, WPF) (x-post from r/Software)\n",
      "\n",
      " * Cool website that explains algorithms as if they are IKEA instruction manuals\n",
      "\n",
      " * How I cut GTA Online loading times by 70%\n",
      "\n",
      " * Linus Torvalds: I think somebody inside of Intel needs to really take a long hard look at their CPU's, and actually admit that they have issues instead of writing PR blurbs that say that everything works as designed.\n",
      "\n",
      " * Inventor says Google is patenting work he put in the public domain\n",
      "\n",
      " * GitHub now gives free users unlimited private repositories\n",
      "\n",
      " * Reddit's main code is no longer open-source.\n",
      "\n",
      " * How We Built r/Place\n",
      "\n",
      " * 18yo arrested for reporting a bug in the new Budapest e-Ticket system\n",
      "\n",
      " * Severe flaw in WPA2 protocol leaves Wi-Fi traffic open to eavesdropping\n"
     ]
    }
   ],
   "source": [
    "print(\"praw version == \" + praw.__version__)\n",
    "\n",
    "# subreddit = r.subreddit(\"programming\")\n",
    "for post in r.subreddit('programming').top(limit=15):\n",
    "    print(end='\\n * ')\n",
    "    print(post.title)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See here a list of other subreddits you can explore with this code: https://www.reddit.com/reddits/\n",
    "\n",
    "To automatically create a data set of reddit users similar to the movie watchers you can invoke the initializeUserDict function in redditrec.py "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1358,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'pijuskri': {}, 'MaxTeo': {}, 'TheFinestPotato': {}, 'Ch16les': {}, 'Mali57': {}, 'vlees': {}, 'GreenHell': {}, 'Marino_NL': {}, 'jdeepankur': {}, 'ShiningChris': {}, 'asd1234red': {}, 'captaingazzz': {}, 'eppur-si-muove-': {}, 'DefinitelyNotASpeedo': {}, 'zeno_5': {}, 'dust-and-disquiet': {}, 'SliccDaddi17': {}, 'degenerateciaagent': {}, 'trollol1365': {}, 'CoastStarlight': {}, 'Bioniclefucker': {}, 'PetrolheadPoop': {}, 'phobiareleased': {}, 'layla_zzz': {}, 'hmm-acha': {}, 'emgoe': {}, 'sammakr': {}, 'ohdGER': {}, 'backpack-kid': {}, 'ZipKip': {}, 'SANCRIUSE': {}, 'HighAssGamer': {}, 'Little-M-Artist': {}, 'JoHeWe': {}, 'FastHenkie': {}, 'thecrashhaker_': {}, 'RepulsiveYesterday': {}, 'deNederlander': {}, 'Wingos80': {}, 'TangentialDust': {}, 'Past_Celebration': {}, 'akaJace': {}, 'MrBeerSon': {}, 'ColonelKross': {}, 'Zapplarang': {}, 'epicaglet': {}, 'rejsuramar': {}, 'celestialruins': {}, 'Drobiczak': {}, 'SystemEarth': {}, '_SpaceJunkie': {}, 'Deputy-Kovacs': {}, 'pk3112': {}, 'Tarchianolix': {}, 'MightyGarhem7': {}, 'NOINSEVUNT': {}, 'DontYouDare69': {}, 'when124566': {}}\n"
     ]
    }
   ],
   "source": [
    "red_users = initializeUserDict('TUDelft', count=5)  # or for any other subreddit\n",
    "print(red_users)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now initializeUserDict has only created the user keys. We of course also want to know what subreddits they posted comments on. You can pull those in through:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1359,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "{'pijuskri': {'TUDelft': 5.0,\n  'europe': 5.0,\n  'lithuania': 2.0,\n  'polandball': 1.0,\n  'Netherlands': 2.0},\n 'MaxTeo': {'Romania': 12.0,\n  'cafeluta': 1.0,\n  '2balkan4you': 1.0,\n  'europe': 1.0},\n 'TheFinestPotato': {'CharacterRant': 2.0,\n  'NoahGetTheBoat': 4.0,\n  'IdiotsInCars': 1.0,\n  'ffxiv': 6.0,\n  'ActualPublicFreakouts': 1.0,\n  'ffxivdiscussion': 1.0},\n 'Ch16les': {'france': 1.0,\n  'formuladank': 3.0,\n  'TUDelft': 3.0,\n  'MathHelp': 2.0,\n  'AerospaceEngineering': 3.0,\n  'IBO': 2.0,\n  'starterpacks': 1.0},\n 'Mali57': {'religion': 1.0,\n  'TUDelft': 2.0,\n  'formula1': 11.0,\n  'scuderiaferrari': 1.0},\n 'vlees': {'strobecirclejerk': 1.0,\n  'TrackMania': 1.0,\n  'justneckbeardthings': 1.0,\n  'RedditAndChill': 1.0,\n  'designedtodefraud': 2.0,\n  'TOXIKK': 1.0,\n  'newworldgame': 2.0,\n  'masterhacker': 1.0,\n  'Vadiboys': 1.0,\n  'KamikazeByWords': 2.0,\n  'bonehurtingjuice': 1.0,\n  'Zombie_Leader': 1.0},\n 'GreenHell': {'motorfietsen': 1.0,\n  'cirkeltrek': 1.0,\n  'InfrastructurePorn': 1.0,\n  'tokkiefeesboek': 7.0,\n  'UrbanHell': 1.0,\n  'thenetherlands': 4.0},\n 'Marino_NL': {'ik_ihe': 1.0,\n  'TommyKay': 5.0,\n  'RoughRomanMemes': 1.0,\n  'blursed_videos': 1.0,\n  'nextfuckinglevel': 1.0,\n  'PublicFreakout': 3.0,\n  'ActualPublicFreakouts': 1.0,\n  'NoahGetTheBoat': 1.0,\n  'tokkiemarktplaats': 1.0},\n 'jdeepankur': {'openttd': 6.0,\n  'MapPorn': 1.0,\n  'tvtropes': 1.0,\n  'Kerala': 2.0,\n  'TrueFilm': 1.0,\n  'MarvelStudiosPlus': 1.0,\n  'movies': 1.0,\n  'books': 1.0,\n  'SubredditDrama': 1.0},\n 'ShiningChris': {'notjustbikes': 3.0,\n  'robac': 10.0,\n  'nanocurrency': 1.0,\n  'TUDelft': 1.0},\n 'asd1234red': {'Chennai': 1.0,\n  'PrinceOfPersia': 4.0,\n  'TUDelft': 1.0,\n  'india': 9.0},\n 'captaingazzz': {'insurgency': 2.0,\n  'AskReddit': 2.0,\n  'thenetherlands': 1.0,\n  'halo': 2.0,\n  'Jokes': 1.0,\n  'rally': 3.0,\n  'nietdespeld': 1.0,\n  'ik_ihe': 1.0,\n  'forza': 2.0},\n 'eppur-si-muove-': {},\n 'DefinitelyNotASpeedo': {'TUDelft': 3.0,\n  'blenderhelp': 1.0,\n  'mathmemes': 1.0,\n  'selffuck': 1.0,\n  'RecruitCS': 3.0,\n  'AskReddit': 1.0,\n  'PUBATTLEGROUNDS': 1.0,\n  'brooklynninenine': 1.0,\n  'battlestations': 1.0,\n  'lotrmemes': 1.0,\n  'comics': 1.0},\n 'zeno_5': {'pics': 2.0, 'TUDelft': 4.0, 'Music': 4.0, 'singing': 5.0},\n 'dust-and-disquiet': {'popheadscirclejerk': 5.0,\n  'ambien': 6.0,\n  'bangladesh': 1.0,\n  'TUDelft': 1.0,\n  'tarot': 1.0,\n  'Drugs': 1.0},\n 'SliccDaddi17': {'NYGiants': 1.0,\n  'ClashRoyale': 2.0,\n  'TUDelft': 3.0,\n  'AnarchyChess': 1.0,\n  'AskMen': 1.0,\n  'italy': 4.0,\n  'leaves': 1.0,\n  'AskReddit': 1.0,\n  'greentext': 1.0},\n 'degenerateciaagent': {'science': 1.0,\n  'Entrepreneur': 1.0,\n  'IntellectualDarkWeb': 3.0,\n  'Damnthatsinteresting': 1.0,\n  'JusticeServed': 1.0,\n  'AskReddit': 1.0,\n  'slatestarcodex': 1.0,\n  'AnarchyChess': 1.0,\n  'hacking': 2.0,\n  'transhumanism': 1.0,\n  'neuro': 1.0,\n  'AerospaceEngineering': 1.0},\n 'trollol1365': {'ToiletPaperUSA': 1.0,\n  'TUDelft': 2.0,\n  'buildapc': 1.0,\n  'tylerthecreator': 1.0,\n  'WhitePeopleTwitter': 2.0,\n  'PoliticalCompassMemes': 2.0,\n  'unpopularopinion': 1.0,\n  '2balkan4you': 1.0,\n  'Kanye': 1.0,\n  'pcmasterrace': 1.0,\n  'europe': 1.0,\n  'TheLastAirbender': 1.0},\n 'CoastStarlight': {'NetherlandsHousing': 4.0,\n  'TUDelft': 1.0,\n  'thenetherlands': 5.0,\n  'TheHague': 1.0,\n  'PhD': 3.0},\n 'Bioniclefucker': {'nonutnovember': 9.0,\n  '196': 2.0,\n  'BreadTube': 1.0,\n  'tumblr': 1.0,\n  '2meirl4meirl': 1.0,\n  'AskReddit': 1.0},\n 'PetrolheadPoop': {'Chodi': 2.0,\n  'TUDelft': 3.0,\n  'IndianFootball': 4.0,\n  'Cricket': 3.0,\n  'NatureIsFuckingLit': 1.0,\n  'Sino': 1.0,\n  'bakchodi': 1.0},\n 'phobiareleased': {'PokemonGoRaids': 6.0, 'TUDelft': 4.0},\n 'layla_zzz': {'TUDelft': 2.0},\n 'hmm-acha': {'india': 2.0,\n  'mumbai': 1.0,\n  'BollyBlindsNGossip': 4.0,\n  'religiousfruitcake': 1.0,\n  'simrankaurr': 1.0,\n  'TanmayBhatKeDost': 1.0,\n  'formuladank': 1.0,\n  'IndiaSpeaks': 1.0,\n  'InstaCelebsGossip': 1.0,\n  'Cuckold': 1.0,\n  'AskReddit': 1.0},\n 'emgoe': {'dating': 1.0, 'ClimateMemes': 5.0, 'TUDelft': 8.0, 'analog': 1.0},\n 'sammakr': {'accenture': 1.0,\n  'DivergeGravelBikes': 2.0,\n  'Delft': 1.0,\n  'Superstonk': 7.0,\n  'RocketLeague': 1.0,\n  'Coronavirus': 2.0,\n  'RocketLeagueExchange': 1.0},\n 'ohdGER': {'howmuchwouldyoupay': 1.0,\n  'InternetIsBeautiful': 2.0,\n  'TUDelft': 6.0,\n  'tumunich': 2.0,\n  'datascience': 1.0,\n  'Damnthatsinteresting': 1.0,\n  'ArtificialInteligence': 2.0},\n 'backpack-kid': {'TUDelft': 1.0,\n  'mac': 7.0,\n  'battlestations': 1.0,\n  'memes': 1.0,\n  'Showerthoughts': 1.0,\n  'aviation': 2.0,\n  'AskReddit': 1.0,\n  'teslamotors': 1.0},\n 'ZipKip': {'antiwork': 1.0,\n  'MkeBucks': 10.0,\n  'insanepeoplefacebook': 1.0,\n  'Netherlands': 1.0,\n  'nba': 1.0,\n  'NYKnicks': 1.0},\n 'SANCRIUSE': {'teenagers': 1.0,\n  'APStudents': 1.0,\n  'cscareerquestions': 1.0,\n  'uwaterloo': 1.0,\n  'UIUC': 5.0,\n  'MBA': 2.0,\n  'csMajors': 1.0,\n  'UBC': 3.0},\n 'HighAssGamer': {'initiativeq': 1.0,\n  'TUDelft': 1.0,\n  'CoinBase': 2.0,\n  'wallstreetbets': 5.0,\n  'trading212': 1.0,\n  'sustainability': 2.0,\n  'environment': 2.0,\n  'ClimateOffensive': 1.0},\n 'Little-M-Artist': {'TUDelft': 2.0},\n 'JoHeWe': {'Yogscast': 2.0,\n  'thenetherlands': 8.0,\n  'antiwork': 1.0,\n  'europe': 3.0,\n  'Jokes': 1.0},\n 'FastHenkie': {'aviation': 1.0,\n  'Porsche': 2.0,\n  'BMW': 4.0,\n  'dankmemes': 2.0,\n  'eindhoven': 1.0,\n  'Delft': 1.0,\n  'CryptoCurrency': 1.0,\n  'formuladank': 1.0,\n  'lego': 1.0,\n  'Ferrari': 1.0},\n 'thecrashhaker_': {'teenagers': 1.0,\n  'DnD': 3.0,\n  'OnePiece': 1.0,\n  'TUDelft': 1.0,\n  'MemePiece': 2.0,\n  'wholesomememes': 3.0,\n  'insanepeoplefacebook': 1.0,\n  'dankmemes': 2.0,\n  'TIHI': 1.0},\n 'RepulsiveYesterday': {'AnimalCrossing': 15.0},\n 'deNederlander': {'DutchFIRE': 2.0,\n  'thenetherlands': 5.0,\n  'Altium': 1.0,\n  'videos': 1.0,\n  'AskEngineers': 1.0,\n  'geldzaken': 2.0,\n  'technology': 1.0,\n  'FPGA': 1.0,\n  'ProgrammerHumor': 1.0},\n 'Wingos80': {'bodyweightfitness': 10.0,\n  'victoria2': 1.0,\n  'eu4': 1.0,\n  'ClimbingCircleJerk': 1.0,\n  'TUDelft': 1.0,\n  '6thForm': 1.0},\n 'TangentialDust': {'thenetherlands': 1.0,\n  'magicTCG': 1.0,\n  'iRacing': 1.0,\n  'simracing': 1.0,\n  'Netherlands': 1.0,\n  'MovieDetails': 1.0,\n  'NatureIsFuckingLit': 1.0,\n  'formuladank': 2.0,\n  'formula1': 5.0,\n  'guitars': 1.0},\n 'Past_Celebration': {'AskReddit': 13.0,\n  'SmashBrosUltimate': 1.0,\n  'smashbros': 1.0},\n 'akaJace': {'EngineeringStudents': 7.0,\n  'halo': 3.0,\n  'Surface': 1.0,\n  'Rainmeter': 2.0,\n  'MacMiller': 1.0,\n  'LudwigAhgren': 1.0},\n 'MrBeerSon': {'pyrocynical': 2.0,\n  'ApplyingToCollege': 1.0,\n  'EliteDangerous': 7.0,\n  'UniUK': 1.0,\n  'buildapc': 2.0,\n  'TUDelft': 1.0,\n  'chanceme': 1.0},\n 'ColonelKross': {'MechanicalKeyboards': 1.0,\n  'battlefield2042': 2.0,\n  'NR200': 3.0,\n  'Slovenia': 4.0,\n  'bikewrench': 4.0,\n  'Justridingalong': 1.0},\n 'Zapplarang': {'btd6': 3.0,\n  'baseball': 5.0,\n  'Tinder': 1.0,\n  'comedyheaven': 1.0,\n  'survivor': 2.0,\n  'battles2': 2.0,\n  'AskReddit': 1.0},\n 'epicaglet': {'ANormalDayInRussia': 2.0,\n  'trashy': 1.0,\n  'blackmagicfuckery': 6.0,\n  'PhantomBorders': 1.0,\n  'specializedtools': 1.0,\n  'uselessredcircle': 1.0,\n  'Unexpected': 1.0,\n  'ProgrammerHumor': 1.0,\n  'explainlikedrcox': 1.0},\n 'rejsuramar': {'StructuralEngineering': 1.0,\n  'malefashionadvice': 13.0,\n  'Seattle': 1.0},\n 'celestialruins': {'bangalore': 1.0,\n  'NZXT': 1.0,\n  'india': 1.0,\n  'teenagers': 1.0,\n  'slavelabour': 2.0,\n  'Netherlands': 1.0,\n  'VALORANT': 3.0,\n  'youngpeopleyoutube': 1.0,\n  'technicallythetruth': 1.0,\n  'AMA': 1.0,\n  'interestingasfuck': 2.0},\n 'Drobiczak': {'synthesizers': 4.0,\n  'KGATLW': 5.0,\n  'MechanicalKeyboards': 1.0,\n  'indieheads': 1.0,\n  'guitarcirclejerk': 2.0,\n  'gamedev': 1.0,\n  'okbuddyretard': 1.0},\n 'SystemEarth': {'thenetherlands': 6.0,\n  'NoStupidQuestions': 1.0,\n  'rugbyunion': 1.0,\n  'TUDelft': 2.0,\n  'southafrica': 1.0,\n  'russian': 1.0,\n  'teenagers': 1.0,\n  'Netherlands': 2.0},\n '_SpaceJunkie': {'germanshepherds': 2.0,\n  'StandingDesks': 1.0,\n  'Python': 3.0,\n  'AskProgramming': 1.0,\n  'learnpython': 8.0},\n 'Deputy-Kovacs': {'NoStupidQuestions': 1.0,\n  'oddlyterrifying': 1.0,\n  'BeginnerPhotoCritique': 1.0,\n  'climbing': 1.0,\n  'Porsche': 7.0,\n  'liberalgunowners': 1.0,\n  'EngineeringStudents': 1.0,\n  'hockeyjerseys': 2.0},\n 'pk3112': {'TUDelft': 15.0},\n 'Tarchianolix': {'aviation': 1.0,\n  'facepalm': 1.0,\n  'StardewValley': 2.0,\n  'WhitePeopleTwitter': 1.0,\n  'coolguides': 1.0,\n  'Wellthatsucks': 1.0,\n  'Showerthoughts': 2.0,\n  'pics': 1.0,\n  'LifeProTips': 1.0,\n  'Damnthatsinteresting': 1.0,\n  'OldSchoolCool': 1.0,\n  'AskMen': 1.0,\n  'LivestreamFail': 1.0},\n 'MightyGarhem7': {'thenetherlands': 1.0,\n  'ketamine': 1.0,\n  'sportsbook': 1.0,\n  'cocaine': 1.0,\n  'PhotoshopRequest': 3.0,\n  'Tinder': 3.0,\n  'GoodNotes': 1.0,\n  'calculus': 1.0,\n  'EngineeringStudents': 2.0,\n  'QualityReps': 1.0},\n 'NOINSEVUNT': {'gay_irl': 1.0,\n  'CuratedTumblr': 1.0,\n  'NewGreentexts': 1.0,\n  'femboy_irl': 2.0,\n  'me_irlgbt': 1.0,\n  'fempark': 2.0,\n  'okbuddyhetero': 3.0,\n  'greentext': 1.0,\n  'VRchat': 1.0,\n  'GaySoundsShitposts': 1.0,\n  'Undertale': 1.0},\n 'DontYouDare69': {'UniversityofTwente': 1.0,\n  'TUDelft': 8.0,\n  'pop_os': 2.0,\n  'utwente': 1.0,\n  'robac': 3.0},\n 'when124566': {'AlzheimersGroup': 2.0,\n  'ComedyNecrophilia': 6.0,\n  'u_when124566': 2.0,\n  'polls': 3.0,\n  'Sinkpissers': 1.0,\n  'ShittyLifeProTips': 1.0}}"
     },
     "execution_count": 1359,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fillItems(red_users, count=15)\n",
    "# here you can see how often each user commented in what sub."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This script may take a few minutes to collect all the data. Use this time to review what is going on in the code. Notice that users don't give ratings to subreddits, instead we are counting how many comments they posted in each subreddit. \n",
    "\n",
    "To recommend a similar user, we can use our topMatches function again.\n",
    "\n",
    "First choose a random user for whom you're going to find neighbours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1360,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rejsuramar\n"
     ]
    },
    {
     "data": {
      "text/plain": "[(0, 'zeno_5'),\n (0, 'when124566'),\n (0, 'vlees'),\n (0, 'trollol1365'),\n (0, 'thecrashhaker_')]"
     },
     "execution_count": 1360,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "user = random.choice(list(red_users.keys()))\n",
    "print(user)  # print the username\n",
    "topMatches(user, prefs=red_users)  # from all redditors, get the most similar to user"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If no similar user was found, you can try increasing the count of users or comments for each initializeUserDict and fillItems."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*****************************************************\n",
    "#### Task: Recommend subreddits for a user based on what subreddits similar users have commented in. Recommend posts for a user based on posts they have commented on. \n",
    "*****************************************************"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1361,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'pijuskri': {'TUDelft': 5.0, 'europe': 5.0, 'lithuania': 2.0, 'polandball': 1.0, 'Netherlands': 2.0}, 'MaxTeo': {'Romania': 12.0, 'cafeluta': 1.0, '2balkan4you': 1.0, 'europe': 1.0}, 'TheFinestPotato': {'CharacterRant': 2.0, 'NoahGetTheBoat': 4.0, 'IdiotsInCars': 1.0, 'ffxiv': 6.0, 'ActualPublicFreakouts': 1.0, 'ffxivdiscussion': 1.0}, 'Ch16les': {'france': 1.0, 'formuladank': 3.0, 'TUDelft': 3.0, 'MathHelp': 2.0, 'AerospaceEngineering': 3.0, 'IBO': 2.0, 'starterpacks': 1.0}, 'Mali57': {'religion': 1.0, 'TUDelft': 2.0, 'formula1': 11.0, 'scuderiaferrari': 1.0}, 'vlees': {'strobecirclejerk': 1.0, 'TrackMania': 1.0, 'justneckbeardthings': 1.0, 'RedditAndChill': 1.0, 'designedtodefraud': 2.0, 'TOXIKK': 1.0, 'newworldgame': 2.0, 'masterhacker': 1.0, 'Vadiboys': 1.0, 'KamikazeByWords': 2.0, 'bonehurtingjuice': 1.0, 'Zombie_Leader': 1.0}, 'GreenHell': {'motorfietsen': 1.0, 'cirkeltrek': 1.0, 'InfrastructurePorn': 1.0, 'tokkiefeesboek': 7.0, 'UrbanHell': 1.0, 'thenetherlands': 4.0}, 'Marino_NL': {'ik_ihe': 1.0, 'TommyKay': 5.0, 'RoughRomanMemes': 1.0, 'blursed_videos': 1.0, 'nextfuckinglevel': 1.0, 'PublicFreakout': 3.0, 'ActualPublicFreakouts': 1.0, 'NoahGetTheBoat': 1.0, 'tokkiemarktplaats': 1.0}, 'jdeepankur': {'openttd': 6.0, 'MapPorn': 1.0, 'tvtropes': 1.0, 'Kerala': 2.0, 'TrueFilm': 1.0, 'MarvelStudiosPlus': 1.0, 'movies': 1.0, 'books': 1.0, 'SubredditDrama': 1.0}, 'ShiningChris': {'notjustbikes': 3.0, 'robac': 10.0, 'nanocurrency': 1.0, 'TUDelft': 1.0}, 'asd1234red': {'Chennai': 1.0, 'PrinceOfPersia': 4.0, 'TUDelft': 1.0, 'india': 9.0}, 'captaingazzz': {'insurgency': 2.0, 'AskReddit': 2.0, 'thenetherlands': 1.0, 'halo': 2.0, 'Jokes': 1.0, 'rally': 3.0, 'nietdespeld': 1.0, 'ik_ihe': 1.0, 'forza': 2.0}, 'eppur-si-muove-': {}, 'DefinitelyNotASpeedo': {'TUDelft': 3.0, 'blenderhelp': 1.0, 'mathmemes': 1.0, 'selffuck': 1.0, 'RecruitCS': 3.0, 'AskReddit': 1.0, 'PUBATTLEGROUNDS': 1.0, 'brooklynninenine': 1.0, 'battlestations': 1.0, 'lotrmemes': 1.0, 'comics': 1.0}, 'zeno_5': {'pics': 2.0, 'TUDelft': 4.0, 'Music': 4.0, 'singing': 5.0}, 'dust-and-disquiet': {'popheadscirclejerk': 5.0, 'ambien': 6.0, 'bangladesh': 1.0, 'TUDelft': 1.0, 'tarot': 1.0, 'Drugs': 1.0}, 'SliccDaddi17': {'NYGiants': 1.0, 'ClashRoyale': 2.0, 'TUDelft': 3.0, 'AnarchyChess': 1.0, 'AskMen': 1.0, 'italy': 4.0, 'leaves': 1.0, 'AskReddit': 1.0, 'greentext': 1.0}, 'degenerateciaagent': {'science': 1.0, 'Entrepreneur': 1.0, 'IntellectualDarkWeb': 3.0, 'Damnthatsinteresting': 1.0, 'JusticeServed': 1.0, 'AskReddit': 1.0, 'slatestarcodex': 1.0, 'AnarchyChess': 1.0, 'hacking': 2.0, 'transhumanism': 1.0, 'neuro': 1.0, 'AerospaceEngineering': 1.0}, 'trollol1365': {'ToiletPaperUSA': 1.0, 'TUDelft': 2.0, 'buildapc': 1.0, 'tylerthecreator': 1.0, 'WhitePeopleTwitter': 2.0, 'PoliticalCompassMemes': 2.0, 'unpopularopinion': 1.0, '2balkan4you': 1.0, 'Kanye': 1.0, 'pcmasterrace': 1.0, 'europe': 1.0, 'TheLastAirbender': 1.0}, 'CoastStarlight': {'NetherlandsHousing': 4.0, 'TUDelft': 1.0, 'thenetherlands': 5.0, 'TheHague': 1.0, 'PhD': 3.0}, 'Bioniclefucker': {'nonutnovember': 9.0, '196': 2.0, 'BreadTube': 1.0, 'tumblr': 1.0, '2meirl4meirl': 1.0, 'AskReddit': 1.0}, 'PetrolheadPoop': {'Chodi': 2.0, 'TUDelft': 3.0, 'IndianFootball': 4.0, 'Cricket': 3.0, 'NatureIsFuckingLit': 1.0, 'Sino': 1.0, 'bakchodi': 1.0}, 'phobiareleased': {'PokemonGoRaids': 6.0, 'TUDelft': 4.0}, 'layla_zzz': {'TUDelft': 2.0}, 'hmm-acha': {'india': 2.0, 'mumbai': 1.0, 'BollyBlindsNGossip': 4.0, 'religiousfruitcake': 1.0, 'simrankaurr': 1.0, 'TanmayBhatKeDost': 1.0, 'formuladank': 1.0, 'IndiaSpeaks': 1.0, 'InstaCelebsGossip': 1.0, 'Cuckold': 1.0, 'AskReddit': 1.0}, 'emgoe': {'dating': 1.0, 'ClimateMemes': 5.0, 'TUDelft': 8.0, 'analog': 1.0}, 'sammakr': {'accenture': 1.0, 'DivergeGravelBikes': 2.0, 'Delft': 1.0, 'Superstonk': 7.0, 'RocketLeague': 1.0, 'Coronavirus': 2.0, 'RocketLeagueExchange': 1.0}, 'ohdGER': {'howmuchwouldyoupay': 1.0, 'InternetIsBeautiful': 2.0, 'TUDelft': 6.0, 'tumunich': 2.0, 'datascience': 1.0, 'Damnthatsinteresting': 1.0, 'ArtificialInteligence': 2.0}, 'backpack-kid': {'TUDelft': 1.0, 'mac': 7.0, 'battlestations': 1.0, 'memes': 1.0, 'Showerthoughts': 1.0, 'aviation': 2.0, 'AskReddit': 1.0, 'teslamotors': 1.0}, 'ZipKip': {'antiwork': 1.0, 'MkeBucks': 10.0, 'insanepeoplefacebook': 1.0, 'Netherlands': 1.0, 'nba': 1.0, 'NYKnicks': 1.0}, 'SANCRIUSE': {'teenagers': 1.0, 'APStudents': 1.0, 'cscareerquestions': 1.0, 'uwaterloo': 1.0, 'UIUC': 5.0, 'MBA': 2.0, 'csMajors': 1.0, 'UBC': 3.0}, 'HighAssGamer': {'initiativeq': 1.0, 'TUDelft': 1.0, 'CoinBase': 2.0, 'wallstreetbets': 5.0, 'trading212': 1.0, 'sustainability': 2.0, 'environment': 2.0, 'ClimateOffensive': 1.0}, 'Little-M-Artist': {'TUDelft': 2.0}, 'JoHeWe': {'Yogscast': 2.0, 'thenetherlands': 8.0, 'antiwork': 1.0, 'europe': 3.0, 'Jokes': 1.0}, 'FastHenkie': {'aviation': 1.0, 'Porsche': 2.0, 'BMW': 4.0, 'dankmemes': 2.0, 'eindhoven': 1.0, 'Delft': 1.0, 'CryptoCurrency': 1.0, 'formuladank': 1.0, 'lego': 1.0, 'Ferrari': 1.0}, 'thecrashhaker_': {'teenagers': 1.0, 'DnD': 3.0, 'OnePiece': 1.0, 'TUDelft': 1.0, 'MemePiece': 2.0, 'wholesomememes': 3.0, 'insanepeoplefacebook': 1.0, 'dankmemes': 2.0, 'TIHI': 1.0}, 'RepulsiveYesterday': {'AnimalCrossing': 15.0}, 'deNederlander': {'DutchFIRE': 2.0, 'thenetherlands': 5.0, 'Altium': 1.0, 'videos': 1.0, 'AskEngineers': 1.0, 'geldzaken': 2.0, 'technology': 1.0, 'FPGA': 1.0, 'ProgrammerHumor': 1.0}, 'Wingos80': {'bodyweightfitness': 10.0, 'victoria2': 1.0, 'eu4': 1.0, 'ClimbingCircleJerk': 1.0, 'TUDelft': 1.0, '6thForm': 1.0}, 'TangentialDust': {'thenetherlands': 1.0, 'magicTCG': 1.0, 'iRacing': 1.0, 'simracing': 1.0, 'Netherlands': 1.0, 'MovieDetails': 1.0, 'NatureIsFuckingLit': 1.0, 'formuladank': 2.0, 'formula1': 5.0, 'guitars': 1.0}, 'Past_Celebration': {'AskReddit': 13.0, 'SmashBrosUltimate': 1.0, 'smashbros': 1.0}, 'akaJace': {'EngineeringStudents': 7.0, 'halo': 3.0, 'Surface': 1.0, 'Rainmeter': 2.0, 'MacMiller': 1.0, 'LudwigAhgren': 1.0}, 'MrBeerSon': {'pyrocynical': 2.0, 'ApplyingToCollege': 1.0, 'EliteDangerous': 7.0, 'UniUK': 1.0, 'buildapc': 2.0, 'TUDelft': 1.0, 'chanceme': 1.0}, 'ColonelKross': {'MechanicalKeyboards': 1.0, 'battlefield2042': 2.0, 'NR200': 3.0, 'Slovenia': 4.0, 'bikewrench': 4.0, 'Justridingalong': 1.0}, 'Zapplarang': {'btd6': 3.0, 'baseball': 5.0, 'Tinder': 1.0, 'comedyheaven': 1.0, 'survivor': 2.0, 'battles2': 2.0, 'AskReddit': 1.0}, 'epicaglet': {'ANormalDayInRussia': 2.0, 'trashy': 1.0, 'blackmagicfuckery': 6.0, 'PhantomBorders': 1.0, 'specializedtools': 1.0, 'uselessredcircle': 1.0, 'Unexpected': 1.0, 'ProgrammerHumor': 1.0, 'explainlikedrcox': 1.0}, 'rejsuramar': {'StructuralEngineering': 1.0, 'malefashionadvice': 13.0, 'Seattle': 1.0}, 'celestialruins': {'bangalore': 1.0, 'NZXT': 1.0, 'india': 1.0, 'teenagers': 1.0, 'slavelabour': 2.0, 'Netherlands': 1.0, 'VALORANT': 3.0, 'youngpeopleyoutube': 1.0, 'technicallythetruth': 1.0, 'AMA': 1.0, 'interestingasfuck': 2.0}, 'Drobiczak': {'synthesizers': 4.0, 'KGATLW': 5.0, 'MechanicalKeyboards': 1.0, 'indieheads': 1.0, 'guitarcirclejerk': 2.0, 'gamedev': 1.0, 'okbuddyretard': 1.0}, 'SystemEarth': {'thenetherlands': 6.0, 'NoStupidQuestions': 1.0, 'rugbyunion': 1.0, 'TUDelft': 2.0, 'southafrica': 1.0, 'russian': 1.0, 'teenagers': 1.0, 'Netherlands': 2.0}, '_SpaceJunkie': {'germanshepherds': 2.0, 'StandingDesks': 1.0, 'Python': 3.0, 'AskProgramming': 1.0, 'learnpython': 8.0}, 'Deputy-Kovacs': {'NoStupidQuestions': 1.0, 'oddlyterrifying': 1.0, 'BeginnerPhotoCritique': 1.0, 'climbing': 1.0, 'Porsche': 7.0, 'liberalgunowners': 1.0, 'EngineeringStudents': 1.0, 'hockeyjerseys': 2.0}, 'pk3112': {'TUDelft': 15.0}, 'Tarchianolix': {'aviation': 1.0, 'facepalm': 1.0, 'StardewValley': 2.0, 'WhitePeopleTwitter': 1.0, 'coolguides': 1.0, 'Wellthatsucks': 1.0, 'Showerthoughts': 2.0, 'pics': 1.0, 'LifeProTips': 1.0, 'Damnthatsinteresting': 1.0, 'OldSchoolCool': 1.0, 'AskMen': 1.0, 'LivestreamFail': 1.0}, 'MightyGarhem7': {'thenetherlands': 1.0, 'ketamine': 1.0, 'sportsbook': 1.0, 'cocaine': 1.0, 'PhotoshopRequest': 3.0, 'Tinder': 3.0, 'GoodNotes': 1.0, 'calculus': 1.0, 'EngineeringStudents': 2.0, 'QualityReps': 1.0}, 'NOINSEVUNT': {'gay_irl': 1.0, 'CuratedTumblr': 1.0, 'NewGreentexts': 1.0, 'femboy_irl': 2.0, 'me_irlgbt': 1.0, 'fempark': 2.0, 'okbuddyhetero': 3.0, 'greentext': 1.0, 'VRchat': 1.0, 'GaySoundsShitposts': 1.0, 'Undertale': 1.0}, 'DontYouDare69': {'UniversityofTwente': 1.0, 'TUDelft': 8.0, 'pop_os': 2.0, 'utwente': 1.0, 'robac': 3.0}, 'when124566': {'AlzheimersGroup': 2.0, 'ComedyNecrophilia': 6.0, 'u_when124566': 2.0, 'polls': 3.0, 'Sinkpissers': 1.0, 'ShittyLifeProTips': 1.0}}\n",
      "Distances:\n",
      "1.0\n",
      "0.25\n",
      "0\n",
      "Pearsons:\n",
      "0\n",
      "0\n",
      "0\n",
      "Recommendations:\n",
      "[]\n",
      "[]\n",
      "[(2.0, 'Netherlands'), (1.0, 'teenagers'), (1.0, 'southafrica'), (1.0, 'russian'), (1.0, 'rugbyunion'), (1.0, 'NoStupidQuestions')]\n"
     ]
    }
   ],
   "source": [
    "print(red_users)\n",
    "\n",
    "\n",
    "print ('Distances:')\n",
    "print (sim_distance('TangentialDust', 'FastHenkie',prefs=red_users))\n",
    "print (sim_distance('TangentialDust', 'CoastStarlight',prefs=red_users))\n",
    "print (sim_distance('FastHenkie', 'CoastStarlight', prefs=red_users))\n",
    "\n",
    "print ('Pearsons:')\n",
    "print (sim_pearson('TangentialDust', 'FastHenkie', prefs=red_users))\n",
    "print (sim_pearson('TangentialDust', 'CoastStarlight', prefs=red_users))\n",
    "print (sim_pearson('FastHenkie', 'CoastStarlight', prefs=red_users))\n",
    "\n",
    "\n",
    "\n",
    "print ('Recommendations:')\n",
    "print (getRecommendations('TangentialDust',prefs=red_users)[0:10])\n",
    "print (getRecommendations('FastHenkie',prefs=red_users)[0:10])\n",
    "print (getRecommendations('CoastStarlight',prefs=red_users)[0:10])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}